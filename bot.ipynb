{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNtGo/eDY81vQcA0XFtzU1c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!git clone https://github.com/HSETEAMSPB/BotDeterminant/"],"metadata":{"id":"CtyQUioaX7Fs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt-get update && apt-get install -y libsndfile1 ffmpeg\n","!pip install Cython\n","!pip install nemo_toolkit['all']"],"metadata":{"id":"pFt4YAr4U5yc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import subprocess\n","import nemo\n","import torch\n","import nltk\n","import nemo.collections.asr as nemo_asr\n","\n","\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","\n","asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(model_name=\"stt_en_contextnet_512\")\n","\n","vad_model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n","                                  model='silero_vad',\n","                                  force_reload=True,\n","                                  onnx=False)\n","(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n","\n","if not os.path.exists(\"checkpoints\"):\n","    subprocess.run([\"wget\", \"https://pjreddie.com/media/files/yolov3.weights\"])\n","    subprocess.run([\"mkdir\", \"checkpoints\"])"],"metadata":{"id":"pQIr8QS3hd8_","executionInfo":{"status":"ok","timestamp":1686763974932,"user_tz":-180,"elapsed":12,"user":{"displayName":"0x1CA d","userId":"12106362513601991862"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!apt-get install opus-tools\n","!pip install aiogram\n","!pip install soundfile\n","!pip install nest-asyncio\n","!pip install -q torchaudio\n","!pip install pydub\n","!pip install webrtcvad\n","!pip install -U denoiser\n","!python -m spacy download en_core_web_sm"],"metadata":{"id":"FcR5xCZxWhTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from BotDeterminant.prsr.config import *\n","from BotDeterminant.prsr.parsing import prs\n","from BotDeterminant.cv.predict import cv_recognize\n","from nemo.core.classes.modelPT import path\n","\n","from aiogram import types, executor, Dispatcher, Bot\n","from aiogram.types import ContentType, File, Message, ParseMode, ReplyKeyboardRemove, \\\n","    ReplyKeyboardMarkup, KeyboardButton, \\\n","    InlineKeyboardMarkup, InlineKeyboardButton\n","from aiogram.utils.markdown import text, bold, italic, code, pre\n","from aiogram.dispatcher.filters import Text\n","\n","import os\n","import random\n","import subprocess\n","from pathlib import Path\n","import soundfile as sf\n","import nest_asyncio\n","import pydub\n","import torch\n","import torchaudio\n","from nltk.stem import WordNetLemmatizer\n","\n","from denoiser import pretrained\n","from denoiser.dsp import convert_audio\n","\n","from IPython.display import Audio\n","from pprint import pprint\n","\n","torch.set_num_threads(1)\n","nest_asyncio.apply()"],"metadata":{"id":"eI74iYgQuOEB","executionInfo":{"status":"ok","timestamp":1686764106873,"user_tz":-180,"elapsed":21026,"user":{"displayName":"0x1CA d","userId":"12106362513601991862"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","\n","TOKEN = \"6039927111:AAF3VMIlflb7Gqz-DYrfPzAOMfq0HE6ZpEM\"\n","bot = Bot(token=TOKEN)\n","dp = Dispatcher(bot)\n","\n","use_vad = False\n","use_denoising = False\n","vad_hardness = 0.5\n","\n","log = \"\"\n","\n","def asr_module(file: str, vad: bool, denoise: bool, id) -> str:\n","    \"\"\"\n","    Automatic Speech Recognition module\n","    file: path to .ogg voice message file\n","    vad: responsible for using voice activity detector\n","    rigidity [0.3, 0.7]: determines the stiffness of vad\n","    denoise: responsible for noise reduction tool\n","\n","    Returns: transcription of audio\n","    \"\"\"\n","\n","    def convert() -> str:\n","        \"\"\"\n","        Decodes the opus file to .wav\n","        Returns: decoded file name\n","        \"\"\"\n","        subprocess.run([\"opusdec\", file, f\"decoded_voice{id}.wav\"])\n","        sound = pydub.AudioSegment.from_file(f\"decoded_voice{id}.wav\")\n","        sound = sound.set_frame_rate(16000)\n","        export_name = f\"{os.path.splitext(file)[0]}.wav\"\n","        sound.export(out_f = export_name, format = \"wav\")\n","\n","        return export_name\n","\n","    def vad(file: str):\n","        \"\"\"\n","        Voice Activity Detection\n","        file: path to input .wav file\n","        \"\"\"\n","        wav = read_audio(file, sampling_rate=16000)\n","        # get speech timestamps from full audio file\n","        speech_timestamps = get_speech_timestamps(wav, vad_model, sampling_rate=16000, threshold=vad_hardness)\n","        save_audio(file, collect_chunks(speech_timestamps, wav), sampling_rate=16000)\n","\n","    def denoise(file: str) -> str:\n","        \"\"\"\n","        audio denoiser (facebook research)\n","        file: path to input .wav file\n","        Returns: path to output .wav file with denoised audio\n","        \"\"\"\n","        model = pretrained.dns64().cuda()\n","        wav, sr = torchaudio.load(file)\n","        wav = convert_audio(wav.cuda(), sr, model.sample_rate, model.chin)\n","        with torch.no_grad():\n","            denoised = model(wav[None])[0]\n","        torchaudio.save(file, denoised.data.cpu(), 16000)\n","\n","    encoded = [convert()]\n","\n","    if use_denoising:\n","        denoise(encoded)\n","    if use_vad:\n","        speech = vad(encoded)\n","\n","    out = asr_model.transcribe(paths2audio_files=encoded)[0][0]\n","    return out\n","\n","\n","\n","# menu keyboard\n","kb = [\n","        [types.KeyboardButton(text=\"vad hardness\")],\n","        [types.KeyboardButton(text=\"noise reduction\")],\n","        [types.KeyboardButton(text=\"log info\")]\n","    ]\n","keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True, keyboard=kb)\n","\n","@dp.message_handler(commands=['start'])\n","async def begin(message: types.Message):\n","    await bot.send_message(message.chat.id, text(\"Wassup! Welcome to picture and voice recognition bot.\",\n","                                            \"To take advantage of me send an image first, then a voice message\",\n","                                            \"\\n\\nYou have the following options:\\n\",\n","                                            \"[<b>noise reduction</b>] - you can connect the removal of background noise when recognizing audio\\n\",\n","                                            \"[<b>vad hardness</b>] - you can set a threshold for voice activity detector\"),\n","                                            reply_markup=keyboard, parse_mode=types.ParseMode.HTML)\n","\n","@dp.message_handler(Text(\"log info\"))\n","async def log_info(message: types.Message):\n","    await message.answer(log, reply_markup=keyboard)\n","\n","@dp.message_handler(Text(\"noise reduction\"))\n","async def vad_hardness(message: types.Message):\n","    kb = [\n","        [types.KeyboardButton(text=\"enable\")],\n","        [types.KeyboardButton(text=\"disable\")],\n","    ]\n","    keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True, keyboard=kb)\n","    await message.answer(\"select mode:\",  reply_markup=keyboard)\n","\n","@dp.message_handler(Text(\"vad hardness\"))\n","async def vad_hardness(message: types.Message):\n","    kb = [\n","        [types.KeyboardButton(text=\"low\")],\n","        [types.KeyboardButton(text=\"medium\")],\n","        [types.KeyboardButton(text=\"high\")]\n","    ]\n","    keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True, keyboard=kb)\n","    await message.answer(\"choose the degree of hardness\", reply_markup=keyboard)\n","\n","@dp.message_handler(lambda message: message.text in [\"low\", \"medium\", \"high\", \"enable\", \"disable\"])\n","async def vad_hardness_applying(message: types.Message):\n","    if message.text in [\"low\", \"medium\", \"high\"]:\n","        use_vad = True\n","        if message.text == \"low\":\n","            vad_hardness = 0.3\n","        elif message.text == \"medium\":\n","            vad_hardness = 0.5\n","        else:\n","            vad_hardness = 0.7\n","        await message.answer(\"perfect! you set a \" + message.text + \" vad mode\", reply_markup=keyboard)\n","    else:\n","        if message.text == \"enable\":\n","            use_denoising = True\n","        elif message.text == \"disable\":\n","            use_denoising = False\n","        await message.answer(f\"deoising is {message.text}d\", reply_markup=keyboard)\n","\n","@dp.message_handler(content_types=ContentType.PHOTO)\n","async def process_photo(message: types.Message):\n","    photos = message.photo\n","    photos = photos[-1]\n","    await photos.download(destination=f'pic{message.from_user.id}.jpg')\n","    await message.answer(\"now send a voice\")\n","\n","@dp.message_handler(content_types=[\n","    types.ContentType.VOICE,\n","    types.ContentType.AUDIO,\n","])\n","async def voice_message_handler(message: types.Message):\n","    if message.content_type == types.ContentType.VOICE:\n","        file_id = message.voice.file_id\n","    elif message.content_type == types.ContentType.AUDIO:\n","        file_id = message.audio.file_id\n","    else:\n","        await message.answer(\"Document format not supported :(\")\n","        return\n","\n","    file = await bot.get_file(file_id)\n","    file_path = file.file_path\n","    file_on_disk = Path(\"\", f\"voice{message.from_user.id}.ogg\")\n","    await bot.download_file(file_path, destination=file_on_disk)\n","    if (os.path.exists(f\"pic{message.from_user.id}.jpg\")):\n","        global log\n","        log = \"\"\n","        transcription = asr_module(f\"voice{message.from_user.id}.ogg\", True, True, message.from_user.id)\n","        log += f\"[asr]: {transcription}\\n\"\n","        classes = prs(transcription, class_names)\n","\n","        cv_classes = \", \".join(classes)\n","        cv_classes = \"[\" + cv_classes + \"]\"\n","        cv_recognize(cv_classes, f\"pic{message.from_user.id}.jpg\")\n","\n","        if not len(classes):\n","            log += f\"[parser]: no recognitions\\n\"\n","            await message.answer(\"no classes are recognized, sorry :(\", parse_mode=ParseMode.MARKDOWN)\n","\n","        classes_to_str = \", \".join(classes)\n","        log += f\"[parser]: {classes_to_str}\\n\"\n","        photo = open(f\"detected_pic{message.from_user.id}.jpg\", \"rb\")\n","\n","        names = [f\"pic{message.from_user.id}.jpg\", f\"voice{message.from_user.id}.ogg\", f\"voice{message.from_user.id}.wav\", f\"detected_pic{message.from_user.id}.jpg\", f\"decoded_voice{message.from_user.id}.wav\"]\n","\n","        for name in names:\n","            os.remove(name)\n","\n","        await bot.send_photo(message.from_user.id, photo)\n","    else:\n","        await message.answer(\"send a photo to get started\")\n","\n","executor.start_polling(dp)"],"metadata":{"id":"adyQRou3grbq"},"execution_count":null,"outputs":[]}]}